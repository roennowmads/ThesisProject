#pragma kernel LocalPrefixSum
#pragma kernel GlobalPrefixSum
#pragma kernel RadixReorder


#define GROUP_SIZE 16

StructuredBuffer<uint4> KeysIn;
RWStructuredBuffer<uint4> BucketsOut;
RWStructuredBuffer<uint4> GlobalPrefixSumOut;

StructuredBuffer<uint> KeysInReorder;
RWStructuredBuffer<uint> PrefixSumIn;
RWStructuredBuffer<uint> KeysOut;

RWStructuredBuffer<uint4> ValueScans; //this buffer is 16 times the size the KeysIn buffer. It has the consecutive scans of the counts of 0's, 1's,..., 15's in the input array, in that order.

//Since one thread in LocalPrefixSum handles 4 input values, we need to output 4*16 (64) values to the ValueScan buffer per thread.

groupshared uint4x4 sharedBuffer[GROUP_SIZE];

int bitshift;

[numthreads(GROUP_SIZE, 1, 1)]
void LocalPrefixSum(uint3 groupThreadId : SV_GroupThreadID, uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
    //take first four bits of every input element.
    uint4 keyBits = (KeysIn[DTid.x] >> bitshift) & 0xF;	//take the 4 least significant bits.  //hey this is only 16 bits, but it takes up 128 bits! ah we'll use it for counting so we need it to be potentially large.
    
	//if we're doing 4 bits (16 values) we need compare the 16 values to all values between 0-15 and return 0 or 1 depending on whether they are equal.

	uint4x4 miniBlock0 = uint4x4(
		keyBits.xxxx == uint4(0u, 1u, 2u, 3u), keyBits.xxxx == uint4(4u, 5u, 6u, 7u), 
		keyBits.xxxx == uint4(8u, 9u, 10u, 11u), keyBits.xxxx == uint4(12u, 13u, 14u, 15u));

	uint4x4 miniBlock1 = uint4x4(
		keyBits.yyyy == uint4(0u, 1u, 2u, 3u), keyBits.yyyy == uint4(4u, 5u, 6u, 7u), 
		keyBits.yyyy == uint4(8u, 9u, 10u, 11u), keyBits.yyyy == uint4(12u, 13u, 14u, 15u));

	uint4x4 miniBlock2 = uint4x4(
		keyBits.zzzz == uint4(0u, 1u, 2u, 3u), keyBits.zzzz == uint4(4u, 5u, 6u, 7u), 
		keyBits.zzzz == uint4(8u, 9u, 10u, 11u), keyBits.zzzz == uint4(12u, 13u, 14u, 15u));

	uint4x4 miniBlock3 = uint4x4(
		keyBits.wwww == uint4(0u, 1u, 2u, 3u), keyBits.wwww == uint4(4u, 5u, 6u, 7u), 
		keyBits.wwww == uint4(8u, 9u, 10u, 11u), keyBits.wwww == uint4(12u, 13u, 14u, 15u));
    
	//
	//Here we can store the flags or when we need to reorder the input in the last step.
	//How can the flags help?
	//They are 0 or 1

	//thread local scan: (sequential)

	miniBlock1 += miniBlock0;
	miniBlock2 += miniBlock1;
	miniBlock3 += miniBlock2;

	sharedBuffer[GI] = miniBlock3; //counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u

	GroupMemoryBarrierWithGroupSync();

	//block local scan:
	//if we know how many threads there are in a group, we know how many times we need to do this step (this is probably not the fastest way to do intra block scan). 

	for (uint i = 0u; i < uint(log2(GROUP_SIZE)); i++) {		//log2(256) == 8
		uint4x4 temp = sharedBuffer[GI];

		uint sumOffset = 1 << i;
		if (GI >= sumOffset) { //step0: ignore first elem, step1: ignore first 2 elems, step1: ignore first 4 elems, etc.
			temp += sharedBuffer[GI - sumOffset];
		}
		GroupMemoryBarrierWithGroupSync();
		sharedBuffer[GI] = temp;
		GroupMemoryBarrierWithGroupSync();
	}

	//After this we have all the final sums for each 4 value subblock. Now we need to offset the partial sums with the previous subblocks final sum:

	if (GI > 0) {
		uint4x4 prevSubBlockFinalSum = sharedBuffer[GI-1];

		miniBlock0 += prevSubBlockFinalSum;
		miniBlock1 += prevSubBlockFinalSum;
		miniBlock2 += prevSubBlockFinalSum;
		//miniBlock3 += prevSubBlockFinalSum; // already stored in sharedBuffer[GI], right?
	}


	//it's not as simple as just getting some values. We need to make sure all the local prefix sums are adjusted to the global offsets.
	//Also in each of these threads we're dealing with 4 values that each should create 16 ValueScans values.

	//After the last GroupMemoryBarrierWithGroupSync we have all the local final sums though, so we can do some things by taking the last "groups" last element (biggest sum) as a base value for this "group".
	//These are not final global prefix sums, but that's fine, we can make the global in a later pass. They have "block scope".

	//sharedBuffer[GI][0].x is the block count for the 0's
	//sharedBuffer[GI][3].w is the block count for the 15's

	//so we still need the rest, not just the sums for the block, but every partial sum in the block as well.   //<-- READ THIS!!!

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 0u ] = miniBlock0[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 1u ] = miniBlock0[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 2u ] = miniBlock0[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 3u ] = miniBlock0[3];

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 4u ] = miniBlock1[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 5u ] = miniBlock1[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 6u ] = miniBlock1[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 7u ] = miniBlock1[3];

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 8u ] = miniBlock2[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 9u ] = miniBlock2[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 10u] = miniBlock2[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 11u] = miniBlock2[3];

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 12u] = sharedBuffer[GI][0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 13u] = sharedBuffer[GI][1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 14u] = sharedBuffer[GI][2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 15u] = sharedBuffer[GI][3];

	//Maybe I should store all the values and not just the final one?
	if (GI == (GROUP_SIZE - 1u)) {
		BucketsOut[4u * groupId.x + 0u] = sharedBuffer[GI][0];	//counts of 0u, 1u, 2u, 3u
		BucketsOut[4u * groupId.x + 1u] = sharedBuffer[GI][1];	//counts of 4u, 5u, 6u, 7u
		BucketsOut[4u * groupId.x + 2u] = sharedBuffer[GI][2];	//counts of 8u, 9u, 10u, 11u
		BucketsOut[4u * groupId.x + 3u] = sharedBuffer[GI][3];	//counts of 12u, 13u, 14u, 15u
	}
}

//the number of thread groups will for most of our cases be at least as large as the thread group size. So we need to parallelize the global prefix sum as well.

//4 x uvec4 x NUMBER_OF_THREADGROUPS values. IF the number of values is higher than 4 x uvec4 x GROUP_SIZE, we have to do this global prefix sum in multiple steps, since all the values won't fit in a block.

[numthreads(GROUP_SIZE, 1, 1)]
void GlobalPrefixSum(uint3 groupThreadId : SV_GroupThreadID, uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	//uint dispatchThreadId = DTid.x * 4u;

	//groupId.x * GROUP_SIZE + 16u * DTid.x + 0u;
	//0 * 16 + 16 * 0 + 0 = 0
	//0 * 16 + 16 * 0 + 1 = 1
	//0 * 16 + 16 * 0 + 2 = 2
	//0 * 16 + 16 * 0 + 3 = 3

	//0 * 16 + 16 * 1 + 0 = 1		//overlap!
	//0 * 16 + 16 * 2 + 1 = 3
	//0 * 16 + 16 * 3 + 2 = 5
	//0 * 16 + 16 * 4 + 3 = 7

	//need to make sure the values I get here are from the same block!
	uint4x4 miniBlock0 = uint4x4(
		ValueScans[16u * DTid.x + 0u ], ValueScans[16u * DTid.x + 1u ], 
		ValueScans[16u * DTid.x + 2u ], ValueScans[16u * DTid.x + 3u ]);

	uint4x4 miniBlock1 = uint4x4(
		ValueScans[16u * DTid.x + 4u ], ValueScans[16u * DTid.x + 5u ], 
		ValueScans[16u * DTid.x + 6u ], ValueScans[16u * DTid.x + 7u ]);

	uint4x4 miniBlock2 = uint4x4(
		ValueScans[16u * DTid.x + 8u ], ValueScans[16u * DTid.x + 9u ], 
		ValueScans[16u * DTid.x + 10u], ValueScans[16u * DTid.x + 11u]);

	uint4x4 miniBlock3 = uint4x4(
		ValueScans[16u * DTid.x + 12u], ValueScans[16u * DTid.x + 13u], 
		ValueScans[16u * DTid.x + 14u], ValueScans[16u * DTid.x + 15u]);

	//thread local scan: (sequential)

	//miniBlock1 += miniBlock0;
	//miniBlock2 += miniBlock1;
	//miniBlock3 += miniBlock2;

	//Get the last element of each block (total block sums):
	//The following four uint4's contains the total sums of the values 0-15 (each value individually) from each block:
	//counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u
	//GI as an index only works (if it actually does?) here as long as the number of blocks is <= GROUP_SIZE.
	sharedBuffer[GI] = uint4x4(BucketsOut[4u * GI + 0u], BucketsOut[4u * GI + 1u], BucketsOut[4u * GI + 2u], BucketsOut[4u * GI + 3u]); 

	GroupMemoryBarrierWithGroupSync();

	//block local scan:
	//if we know how many threads there are in a group, we know how many times we need to do this step (this is probably not the fastest way to do intra block scan). 

	for (uint i = 0u; i < uint(log2(GROUP_SIZE)); i++) {		//log2(256) == 8
		uint4x4 temp = sharedBuffer[GI];

		uint sumOffset = 1 << i;
		if (GI >= sumOffset) { //step0: ignore first elem, step1: ignore first 2 elems, step1: ignore first 4 elems, etc.
			temp += sharedBuffer[GI - sumOffset];
		}
		GroupMemoryBarrierWithGroupSync();
		if (GI > 0) {
			sharedBuffer[GI] = temp;
		}
		GroupMemoryBarrierWithGroupSync();
	}

	//After this step the sharedBuffer contains partial and full prefix sums of all the blocks that could fit within one thread group (that is, GROUP_SIZE blocks).

	
	//here we need to take the value from the last BLOCK not the last thread. This complicates things because sharedBuffer is block scope only.
	//The shaderBuffer does contain the partial sums of the blocks though. This kernel was meant to be run only with one thread group, and have all the partial sums within one block.
		
	if (groupId.x > 0) {
		uint4x4 prevSubBlockFinalSum = sharedBuffer[groupId.x-1]; //this gives a new sum for each increase in GI. While we want the same for this group, right?

		miniBlock0 += prevSubBlockFinalSum;
		miniBlock1 += prevSubBlockFinalSum;
		miniBlock2 += prevSubBlockFinalSum;
		miniBlock3 += prevSubBlockFinalSum; // already stored in sharedBuffer[GI], right?
	}

	//miniBlock0[0].x should contain the partial sum of 0's. It appears every 16's index of the ValueScans buffer.

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 0u ] = miniBlock0[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 1u ] = miniBlock0[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 2u ] = miniBlock0[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 3u ] = miniBlock0[3];

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 4u ] = miniBlock1[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 5u ] = miniBlock1[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 6u ] = miniBlock1[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 7u ] = miniBlock1[3];

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 8u ] = miniBlock2[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 9u ] = miniBlock2[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 10u] = miniBlock2[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 11u] = miniBlock2[3];

	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 12u] = miniBlock3[0];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 13u] = miniBlock3[1];
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 14u] = miniBlock3[2]; //make sure this is an exclusive instead of inclusive scan
	ValueScans[/*groupId.x * GROUP_SIZE +*/ 16u * DTid.x + 15u] = miniBlock3[3];

	GroupMemoryBarrierWithGroupSync();  //probably not necessary

	if (groupId.x == 0 && GI == (GROUP_SIZE - 1u)) {
		//this is inclusive scan (needs to be exclusive!)
		//Here we scan the counts of the 16 values, in order to get their base indices.

		/*sharedBuffer[GI][0].y += sharedBuffer[GI][0].x;
		sharedBuffer[GI][0].z += sharedBuffer[GI][0].y;
		sharedBuffer[GI][0].w += sharedBuffer[GI][0].z;

		sharedBuffer[GI][1].x += sharedBuffer[GI][0].w;
		sharedBuffer[GI][1].y += sharedBuffer[GI][1].x;
		sharedBuffer[GI][1].z += sharedBuffer[GI][1].y;
		sharedBuffer[GI][1].w += sharedBuffer[GI][1].z;

		sharedBuffer[GI][2].x += sharedBuffer[GI][1].w;
		sharedBuffer[GI][2].y += sharedBuffer[GI][2].x;
		sharedBuffer[GI][2].z += sharedBuffer[GI][2].y;
		sharedBuffer[GI][2].w += sharedBuffer[GI][2].z;

		sharedBuffer[GI][3].x += sharedBuffer[GI][2].w;
		sharedBuffer[GI][3].y += sharedBuffer[GI][3].x;
		sharedBuffer[GI][3].z += sharedBuffer[GI][3].y;
		sharedBuffer[GI][3].w += sharedBuffer[GI][3].z;*/

		GlobalPrefixSumOut[4u * groupId.x + 0u] = sharedBuffer[GI][0];	//counts of 0u, 1u, 2u, 3u
		GlobalPrefixSumOut[4u * groupId.x + 1u] = sharedBuffer[GI][1];	//counts of 4u, 5u, 6u, 7u
		GlobalPrefixSumOut[4u * groupId.x + 2u] = sharedBuffer[GI][2];	//counts of 8u, 9u, 10u, 11u
		GlobalPrefixSumOut[4u * groupId.x + 3u] = sharedBuffer[GI][3];	//counts of 12u, 13u, 14u, 15u
	}
}


//GlobalPrefixSum returns the indiviual counts for each value 0-15, while we actually need the prefix sum of them.
//Is this actually correct? if it is, then I just need to run a prefix sum on the result, otherwise i need to change something.
//It is correct. It's just that the previous is "horizontal" and we need to do one last "vertical scan".
//For a 16K input array that looks like this: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15, 0,1,2,3, ...], there will 1024 of each of the 16 elements.
//As a last step we need to do an exclusive scan over the 16 buckets, so we get this: 
//[0, 1024, 2048, 3072, 4096, 5120, ...], which we can use as direct index locations for the keyOut array.
//Since there are only 16 of these, we might as well do it in one thread.

//[2,3,5,4] -> [2,5,8,9], [0,2,5,8]

[numthreads(GROUP_SIZE, 1, 1)]
void RadixReorder(uint3 groupThreadId : SV_GroupThreadID, uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	
	//uint keyBits = (KeysInReorder[DTid.x] >> bitshift) & 0xF;
	//uint newIndex0 = PrefixSumIn[bucket];		//+ g_HistogramBuffer[bucket * g_Limit + id.x];
	//KeysOut[newIndex0.x] = key;
}








