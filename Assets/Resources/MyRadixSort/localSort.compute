#pragma kernel LocalPrefixSum
#pragma kernel GlobalPrefixSum
#pragma kernel RadixReorder


#define GROUP_SIZE 512

struct Particle {
	uint key;
	uint depth;
};

StructuredBuffer<uint> KeysIn;
RWStructuredBuffer<uint4x4> BucketsOut;
RWStructuredBuffer<uint4> GlobalPrefixSumOut;
RWStructuredBuffer<uint> ValueScans;

StructuredBuffer<uint> GlobalPrefixSumIn;
StructuredBuffer<uint> ValueScansIn;
RWStructuredBuffer<uint> KeysOut;

StructuredBuffer<float3> _Points;
//this buffer is 16 times the size the KeysIn buffer. It has the consecutive scans of the counts of 0's, 1's,..., 15's in the input array, in that order.

//Since one thread in LocalPrefixSum handles 4 input values, we need to output 4*16 (64) values to the ValueScan buffer per thread.


RWStructuredBuffer<uint> DepthVals;


groupshared uint4x4 sharedBuffer[GROUP_SIZE];

int bitshift;
float4x4 model;
float3 camPos;

[numthreads(GROUP_SIZE, 1, 1)]
void LocalPrefixSum(uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	//uint indexAndColor = Data.Load(DTid.x);
	
	uint key = KeysIn[DTid.x];  //indexAndColor
	float4 transVert = mul(model, float4(-_Points[key >> 8], 1.0));
	float depth = 100000.0 - distance(camPos, transVert.xyz);
	uint intDepth = asuint(depth);
	
	//take four bits of every input element:
	uint keyBits = (intDepth >> bitshift) & 0xF;

	DepthVals[DTid.x] = keyBits;

    
	 //hey this is only 16 bits, but it takes up 128 bits! ah we'll use it for counting so we need it to be potentially large.
	//if we're doing 4 bits (16 values) we need compare the 16 values to all values between 0-15 and return 0 or 1 depending on whether they are equal.
	uint4x4 miniBlock = uint4x4(
		keyBits.xxxx == uint4(0u, 1u, 2u, 3u), keyBits.xxxx == uint4(4u, 5u, 6u, 7u), 
		keyBits.xxxx == uint4(8u, 9u, 10u, 11u), keyBits.xxxx == uint4(12u, 13u, 14u, 15u));

	sharedBuffer[GI] = miniBlock; //counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u

	GroupMemoryBarrierWithGroupSync();

	//block local scan:
	//if we know how many threads there are in a group, we know how many times we need to do this step (this is probably not the fastest way to do intra block scan). 

	{
		[unroll(int(log2(GROUP_SIZE)))]
		for (uint i = 0u; i < uint(log2(GROUP_SIZE)); i++) {		//log2(256) == 8
			uint4x4 temp = sharedBuffer[GI];

			uint sumOffset = 1 << i;
			if (GI >= sumOffset) { //step0: ignore first elem, step1: ignore first 2 elems, step1: ignore first 4 elems, etc.
				temp += sharedBuffer[GI - sumOffset];
			}
			GroupMemoryBarrierWithGroupSync();
			sharedBuffer[GI] = temp;
			GroupMemoryBarrierWithGroupSync();
		}
	}

	//After this we have all the final sums for each 4 value subblock. Now we need to offset the partial sums with the previous subblocks final sum:

	if (GI > 0) {
		miniBlock += sharedBuffer[GI - 1];
	}


	//it's not as simple as just getting some values. We need to make sure all the local prefix sums are adjusted to the global offsets.
	//Also in each of these threads we're dealing with 4 values that each should create 16 ValueScans values.

	//After the last GroupMemoryBarrierWithGroupSync we have all the local final sums though, so we can do some things by taking the last "groups" last element (biggest sum) as a base value for this "group".
	//These are not final global prefix sums, but that's fine, we can make the global in a later pass. They have "block scope".

	//sharedBuffer[GI][0].x is the block count for the 0's
	//sharedBuffer[GI][3].w is the block count for the 15's

	//We only store the values that we actually need to create a local index:
	ValueScans[DTid.x] = ((uint[16])miniBlock)[keyBits];

	if (GI == (GROUP_SIZE - 1u)) {
		BucketsOut[groupId.x] = sharedBuffer[GI]; //counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u
	}
}

//the number of thread groups will for most of our cases be at least as large as the thread group size. So we need to parallelize the global prefix sum as well.

//4 x uvec4 x NUMBER_OF_THREADGROUPS values. IF the number of values is higher than 4 x uvec4 x GROUP_SIZE, we have to do this global prefix sum in multiple steps, since all the values won't fit in a block.

[numthreads(GROUP_SIZE, 1, 1)]
void GlobalPrefixSum(uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	//Get the last element of each block (total block sums):
	//The following four uint4's contains the total sums of the values 0-15 (each value individually) from each block:
	//counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u
	//GI as an index only works (if it actually does?) here as long as the number of blocks is <= GROUP_SIZE.

	sharedBuffer[GI] = BucketsOut[GI];

	GroupMemoryBarrierWithGroupSync();

	//block local scan:
	//if we know how many threads there are in a group, we know how many times we need to do this step (this is probably not the fastest way to do intra block scan). 

	{
		[unroll(int(log2(GROUP_SIZE)))]
		for (uint i = 0u; i < uint(log2(GROUP_SIZE)); i++) {		//log2(256) == 8
			uint4x4 temp = sharedBuffer[GI];

			uint sumOffset = 1 << i;
			if (GI >= sumOffset) { //step0: ignore first elem, step1: ignore first 2 elems, step1: ignore first 4 elems, etc.
				temp += sharedBuffer[GI - sumOffset];
			}
			GroupMemoryBarrierWithGroupSync();
			sharedBuffer[GI] = temp;
			GroupMemoryBarrierWithGroupSync();
		}
	}

	//After this step the sharedBuffer contains partial and full prefix sums of all the blocks that could fit within one thread group (that is, GROUP_SIZE blocks).

	
	//here we need to take the value from the last BLOCK not the last thread. This complicates things because sharedBuffer is block scope only.
	//The shaderBuffer does contain the partial sums of the blocks though. This kernel was meant to be run only with one thread group, and have all the partial sums within one block.

	if (groupId.x == 0 && GI == (GROUP_SIZE - 1u)) {
		//Here we scan the counts of the 16 values, in order to get their base indices.

		//exclusive scan:
		uint prefixSums[16];
		prefixSums[0] = 0u;
		for (uint i = 1u; i < 16u; i++) {
			prefixSums[i] = prefixSums[i - 1] + ((uint[16])sharedBuffer[GI])[i - 1];
		}

		uint4x4 prefixSumsMatrix = uint4x4(prefixSums);
		uint groupOffset = 16u * groupId.x;
		GlobalPrefixSumOut[groupOffset] = prefixSumsMatrix[0];
		GlobalPrefixSumOut[groupOffset + 4u] = prefixSumsMatrix[1];
		GlobalPrefixSumOut[groupOffset + 8u] = prefixSumsMatrix[2];
		GlobalPrefixSumOut[groupOffset + 12u] = prefixSumsMatrix[3];
	}

	if (groupId.x > 0) {
		uint prevSubBlockFinalSum[16] = (uint[16])sharedBuffer[groupId.x - 1]; //this gives a new sum for each increase in GI. While we want the same for this group, right?


		/*uint key = KeysIn[DTid.x];  //indexAndColor
		float4 transVert = mul(model, float4(-_Points[key >> 8], 1.0));
		float depth = 100000.0 - distance(camPos, transVert.xyz);
		uint intDepth = asuint(depth);
		
		//take four bits of every input element:
		uint keyBits = (intDepth >> bitshift) & 0xF;*/

		uint keyBits = DepthVals[DTid.x];

		//uint keyBits = (KeysIn[DTid.x].depth >> bitshift) & 0xF;
		uint prevSum0 = prevSubBlockFinalSum[keyBits];
		ValueScans[DTid.x] += prevSum0; //miniBlock[0][0][0] contains the partial sum of 0's. It appears every 16's index of the ValueScans buffer.
	}	
}


//GlobalPrefixSum returns the indiviual counts for each value 0-15, while we actually need the prefix sum of them.
//Is this actually correct? if it is, then I just need to run a prefix sum on the result, otherwise i need to change something.
//It is correct. It's just that the previous is "horizontal" and we need to do one last "vertical scan".
//For a 16K input array that looks like this: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15, 0,1,2,3, ...], there will 1024 of each of the 16 elements.
//As a last step we need to do an exclusive scan over the 16 buckets, so we get this: 
//[0, 1024, 2048, 3072, 4096, 5120, ...], which we can use as direct index locations for the keyOut array.
//Since there are only 16 of these, we might as well do it in one thread.

//[2,3,5,4] -> [2,5,8,9], [0,2,5,8]

[numthreads(GROUP_SIZE, 1, 1)]
void RadixReorder(uint3 groupThreadId : SV_GroupThreadID, uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	//Particle key = KeysIn[DTid.x];
	uint key = KeysIn[DTid.x];  //indexAndColor
	uint bucket = DepthVals[DTid.x];
	uint globalOffset = GlobalPrefixSumIn[bucket];
	uint localOffset = ValueScansIn[DTid.x] - 1u;  //ValueScansIn, every 16th value is a partial prefix sum of the same value.

	uint newIndex = globalOffset + localOffset;
	KeysOut[newIndex] = key;
}








