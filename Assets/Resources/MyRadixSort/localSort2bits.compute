#pragma kernel LocalPrefixSum
#pragma kernel GlobalPrefixSum
#pragma kernel RadixReorder

StructuredBuffer<uint> KeysIn;
RWStructuredBuffer<uint4> BucketsOut;
RWStructuredBuffer<uint4> GlobalDigitPrefixSumOut;
RWStructuredBuffer<uint> ValueScans;
RWStructuredBuffer<uint4> GlobalPrefixSumOut;

StructuredBuffer<uint4> BucketsIn;

StructuredBuffer<uint4> GlobalPrefixSumIn;
StructuredBuffer<uint4> GlobalDigitPrefixSumIn;
StructuredBuffer<uint> ValueScansIn;
RWStructuredBuffer<uint> KeysOut;

StructuredBuffer<float3> _Points;

struct DepthAndValueScans {
	uint depth;
	uint valueScan;
};

RWStructuredBuffer<DepthAndValueScans> DepthValueScanOut;
StructuredBuffer<DepthAndValueScans> DepthValueScanIn;

#define WARP_SIZE 32
#define GROUP_SIZE 512

#if WARP_SIZE == 64
#define WARP_SHIFT 6   // == log2(64)
#elif WARP_SIZE == 32
#define WARP_SHIFT 5   // == log2(32)
#elif WARP_SIZE == 16                  //optimal for adreno 510
#define WARP_SHIFT 4   // == log2(16)
#endif

groupshared uint4 temp[GROUP_SIZE];

int bitshift;
float4x4 model;
float3 camPos;
float scaledMaxDistance;
float3 objectWorldPos;
float depthIndices;

//source for intra warp scan: 
//http://research.nvidia.com/sites/default/files/publications/nvr-2008-003.pdf



uint4 ScanWarp(uint index, uint lane)
{
	if (lane >= 1)
		temp[index] = temp[index - 1] + temp[index];
	if (lane >= 2)
		temp[index] = temp[index - 2] + temp[index];
	if (lane >= 4)
		temp[index] = temp[index - 4] + temp[index];
	if (lane >= 8)
		temp[index] = temp[index - 8] + temp[index];
#if WARP_SIZE >= 32
	if (lane >= 16)
		temp[index] = temp[index - 16] + temp[index];
#endif
#if WARP_SIZE >= 64
	if (lane >= 32)
		temp[index] = temp[index - 32] + temp[index];
#endif
	return lane > 0 ? temp[index - 1] : uint4(0,0,0,0); //0;
}

uint4 ScanWarpInclusive(uint index, uint lane)
{
	if (lane >= 1)
		temp[index] = temp[index - 1] + temp[index];
	if (lane >= 2)
		temp[index] = temp[index - 2] + temp[index];
	if (lane >= 4)
		temp[index] = temp[index - 4] + temp[index];
	if (lane >= 8)
		temp[index] = temp[index - 8] + temp[index];
#if WARP_SIZE >= 32
	if (lane >= 16)
		temp[index] = temp[index - 16] + temp[index];
#endif
#if WARP_SIZE >= 64
	if (lane >= 32)
		temp[index] = temp[index - 32] + temp[index];
#endif
	return temp[index];
}

uint4 ScanGroup(uint index)
{
	uint lane = index & (WARP_SIZE - 1); // index of thread in warp (0..31)
	uint warpId = index >> WARP_SHIFT;

	// Step 1: Intra-warp scan in each warp
	uint4 val = ScanWarpInclusive(index, lane);
	GroupMemoryBarrierWithGroupSync();

	// Step 2: Collect per-warp partial results
	if (lane == (WARP_SIZE - 1))
		temp[warpId] = temp[index];
	GroupMemoryBarrierWithGroupSync();

	// Step 3: Use 1st warp to scan per-warp results
	if (warpId == 0)
		ScanWarpInclusive(index, lane);
	GroupMemoryBarrierWithGroupSync();

	// Step 4: Accumulate results from Steps 1 and 3
	if (warpId > 0)
		val = val + temp[warpId - 1];
	GroupMemoryBarrierWithGroupSync();

	// Step 5: Write and return the final result
	temp[index] = val;
	GroupMemoryBarrierWithGroupSync();

	return val;
}

[numthreads(GROUP_SIZE, 1, 1)]
void LocalPrefixSum(uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{	
	uint key = KeysIn[DTid.x];  //indexAndColor
	float4 transVert = mul(model, float4(-_Points[key >> 8], 1.0));
	float depth = dot(transVert.xyz - objectWorldPos, camPos);
	float relativeDepth = (depth + scaledMaxDistance) / (scaledMaxDistance + scaledMaxDistance);
	uint intDepth = uint(relativeDepth * depthIndices);	
	
	//take four bits of every input element:
	uint keyBits = 3u - ((intDepth >> bitshift) & 0xF);  // we invert the 0-15 to 15-0 to get a reverse sort	
    

	uint4 miniBlock = uint4(keyBits.xxxx == uint4(0u, 1u, 2u, 3u));

	temp[GI] = miniBlock; //counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u
	GroupMemoryBarrierWithGroupSync();
	uint4 result = ScanGroup(GI);

	DepthValueScanOut[DTid.x].depth = keyBits;
	DepthValueScanOut[DTid.x].valueScan = result[keyBits];

	//Final counts for each block:
	if (GI == (GROUP_SIZE - 1u)) {
		BucketsOut[groupId.x] = result; //counts of 0u, 1u, 2u, 3u, counts of 4u, 5u, 6u, 7u, counts of 8u, 9u, 10u, 11u, counts of 12u, 13u, 14u, 15u
	}
}

//the number of thread groups will for most of our cases be at least as large as the thread group size. So we need to parallelize the global prefix sum as well.

//4 x uvec4 x NUMBER_OF_THREADGROUPS values. IF the number of values is higher than 4 x uvec4 x GROUP_SIZE, we have to do this global prefix sum in multiple steps, since all the values won't fit in a block.

[numthreads(GROUP_SIZE, 1, 1)]
void GlobalPrefixSum(uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	temp[GI] = BucketsIn[GI];
	GroupMemoryBarrierWithGroupSync();
	uint4 result = ScanGroup(GI);

	GlobalPrefixSumOut[GI] = result;

	if (GI == (GROUP_SIZE - 1u)) {
		//Here we scan the counts of the 16 values, in order to get their base indices.

		//exclusive scan:
		uint4 prefixSums;
		prefixSums.x = 0u;
		prefixSums.y = prefixSums.x + result.x;
		prefixSums.z = prefixSums.y + result.y;
		prefixSums.w = prefixSums.z + result.z;

		GlobalDigitPrefixSumOut[0] = prefixSums;
	}
}

//GlobalPrefixSum returns the indiviual counts for each value 0-15, while we actually need the prefix sum of them.
//Is this actually correct? if it is, then I just need to run a prefix sum on the result, otherwise i need to change something.
//It is correct. It's just that the previous is "horizontal" and we need to do one last "vertical scan".
//For a 16K input array that looks like this: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15, 0,1,2,3, ...], there will 1024 of each of the 16 elements.
//As a last step we need to do an exclusive scan over the 16 buckets, so we get this: 
//[0, 1024, 2048, 3072, 4096, 5120, ...], which we can use as direct index locations for the keyOut array.
//Since there are only 16 of these, we might as well do it in one thread.

//[2,3,5,4] -> [2,5,8,9], [0,2,5,8]

[numthreads(GROUP_SIZE, 1, 1)]
void RadixReorder(uint3 groupThreadId : SV_GroupThreadID, uint3 DTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint GI : SV_GroupIndex)
{
	DepthAndValueScans depthValueScans = DepthValueScanIn[DTid.x];
	uint localOffset = depthValueScans.valueScan; //ValueScans, every 16th value is a partial prefix sum of the same value.
	uint keyBits = depthValueScans.depth;

	//Correct the ValueScans according to the Global offset:
	if (groupId.x > 0) {
		uint4 prevBlockFinalSum = GlobalPrefixSumIn[groupId.x - 1]; //this gives a new sum for each increase in GI. While we want the same for this group, right?
		uint prevSum0 = prevBlockFinalSum[keyBits];
		localOffset += prevSum0; //miniBlock[0][0][0] contains the partial sum of 0's. It appears every 16's index of the ValueScans buffer.
	}

	uint key = KeysIn[DTid.x];  //indexAndColor
	uint globalOffset = GlobalDigitPrefixSumIn[0][keyBits];

	uint newIndex = globalOffset + localOffset - 1u;

	//Very uncoalesced writes...
	KeysOut[newIndex] = key;
}








